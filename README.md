# Project-3: Gradient Descent for Rastrigin Function
![Slide](https://cdn.discordapp.com/attachments/297573789095428096/952729673203351613/unknown.png)

# gd/sa with rastringin and other functions
# plotting avg error (distance to actual minima) across multiple iterations for each algorithm
# using gd/sa for machine learning
# don't usually have the actual function, just a set of data that represents the function's input and associated output
# so far minimizing a function without any meaning, but in ml we want to create a model of a function based on its input and output data
# in other words, we are trying to minimize the error of our model with respect to the actual function
# if we could use a function that describes this error, we could apply gd/sa to it to minimize our model's error
# now the function we are minimizing has actual meaning

I went to Thanos' office hours and He said to only include more test functions for the gradient descent. He said to do 2 or 3 more functions(1 convex  , 1 nonconvex) other than the Rastrigin function. Also test with higher dimensions. Explain the behavior of gradient descent with these methods and why some work in convex and why it may get stuck. What also happens when we use higher dimensions. He said all the other projects are fine because all of them were demanding already.
Here is the link with other test functions for the GD
https://wiki2.org/en/Test_functions_for_optimization+Milds.2
